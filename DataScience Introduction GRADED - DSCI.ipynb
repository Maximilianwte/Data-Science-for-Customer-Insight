{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Science for Customer Insights - Python Introduction Course",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maximilianwte/Data-Science-for-Customer-Insight/blob/main/DataScience%20Introduction%20GRADED%20-%20DSCI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "#Data Science for Customer Insights - Datascience Introduction\n",
        "\n",
        "Welcome to Data Science for Customer Insights. In the following tasks, you will learn how to do Data Science with Python. In the end, you will be able to:\n",
        "\n",
        "- do basic coding and use Python loops, lists, functions and more\n",
        "- access and apply machine learning algorithms to data sets\n",
        "- understand fundamental machine learning concepts\n",
        "\n",
        "Please go trough all tasks and answer the questions carefully. **This is task-based learning - you will have to Google a lot**. You can use any credible source material, you like, e.g.:\n",
        "\n",
        "- stackoverflow\n",
        "- SoloLearn\n",
        "- DataCamp\n",
        "- udemy\n",
        "\n",
        "Again - you will potentially have to Google everything, this is normal!\n",
        "\n",
        "Also, every time you see those signs \"**...**\" you have to change them to generate the correct code.\n",
        "\n",
        "**Note: This is the Notebook that part of your grade in the Seminar will be based on.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQWo_jfy4H9s"
      },
      "source": [
        "**Before you start: Please provide your information**\n",
        "\n",
        "Name:\n",
        "\n",
        "Matr.:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basics of Python programming\n",
        "The following cells will ask you about some of the most important concepts of Python programming. If the questions in this section feel quite challenging to you, feel free to work through the Python Introduction Notebook first, to get familiar with Python programming.\n",
        "\n",
        "Link to the Python Introduction Notebook:"
      ],
      "metadata": {
        "id": "jtbk80g3cHLu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt_Y_ZWA9miH"
      },
      "source": [
        "**Multiplication and comments**\n",
        "\n",
        "\n",
        "1. *Replace the '...' in line one to multiply the numerical values in line one*\n",
        "\n",
        "\n",
        "2. You can comment your code, to explain something for later reference.\n",
        "\n",
        "   *Please turn \"This is just a comment\" into a proper comment.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssxN9tka9-2o"
      },
      "source": [
        "4 ... 4\n",
        "This is just a comment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEmilTRFecFV"
      },
      "source": [
        "**Loops**\n",
        "\n",
        "A for loop is used to repeat a block of code multiple times. It is common to use the for loop when the number of iterations is fixed (e.g. iterating over a fixed list of items in a shopping list), but there are other loops as well.\n",
        "\n",
        "*Change the code below to print all elements of your list:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrSVVOz2Uzm9"
      },
      "source": [
        "your_list = ['a','b','c','d']\n",
        "\n",
        "for ... ... ... :\n",
        "  print (...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOEUQc1SVzqh"
      },
      "source": [
        "*Please change the ... to correct the code so that the loop is broken after the loop reaches the 'c' in your list.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYHdF1AVlZYy"
      },
      "source": [
        "for item ... your_list:\n",
        "  print(item)\n",
        "  if item ... ...:\n",
        "    print (\"Breaking\")\n",
        "    ...\n",
        "\n",
        "print(\"Finished\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_wm9FcxVd8T"
      },
      "source": [
        "**Pandas**\n",
        "\n",
        "pandas is a program library for the Python programming language that provides tools for data management and analysis. In particular, it contains data structures and operators for accessing tables and time series.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMs0xplyHutE"
      },
      "source": [
        "*Please import the pandas package as pd:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvlvkfJvH8NK"
      },
      "source": [
        "import ... as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create a numpy 4x4 numpy matrix with random integer values\n",
        "myarr = (np. ... (4,4)*10). ... .astype(int)\n",
        "\n",
        "df = ...(myarr)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "C6rhpHpAcaRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the dataframe using the Loc function to return all numbers that are larger than 3\n",
        "df_larger =\n",
        "print(df_larger)\n",
        "\n",
        "# Delete all rows, where the values are smaller than 5\n",
        "df_delete =\n",
        "print(df_delete)"
      ],
      "metadata": {
        "id": "A-kAlor4e62Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky94Fe9pVu8a"
      },
      "source": [
        "## Basic Machine Learning: Linear Regression using Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KADPUVuDC1w"
      },
      "source": [
        "There are **five basic steps** when you‚Äôre implementing linear regression:\n",
        "\n",
        "1. Import the packages and classes you need.\n",
        "2. Provide data to work with and eventually do appropriate transformations.\n",
        "3. Create a regression model and fit it with existing data.\n",
        "4. Check the results of model fitting to know whether the model is satisfactory.\n",
        "5. Apply the model for predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vxgqggvDgEG"
      },
      "source": [
        "**Step 1: Import packages and classes**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4w2k0VNDzkd"
      },
      "source": [
        "*Please import the package numpy and the class LinearRegression:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOXsjNrzDqTL"
      },
      "source": [
        "import numpy as np\n",
        "from ... import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25zDeGGiEBUw"
      },
      "source": [
        "The fundamental data type of NumPy is the array type called numpy.ndarray. From now on, we're using the term array to refer to instances of the type numpy.ndarray."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qNh58vEEMWL"
      },
      "source": [
        "**Step 2: Provide data:**\n",
        "\n",
        "The second step is defining data to work with. The inputs (regressors, ùë•) and output (predictor, ùë¶) should be arrays (the instances of the class numpy.ndarray) or similar objects. Please reuse X_scaled and y_scaled. If this did not work, use the alternative data provided.\n",
        "\n",
        "*If necessary, change the following code to provide data for the regression:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfhGOPWEuI72"
      },
      "source": [
        "# IF YOU DID NOT MANAGE TO CREATE X_scaled and y_scaled, uncomment and use the following lines\n",
        "# X_scaled = np.array([-0.51,  0.67, -0.47,  0.6 ,  1.71, -0.16,  0.34, -1.02, -0.68,\n",
        "#         2.43, -1.2 ,  0.51, -0.91,  0.66, -0.53, -2.31, -0.65,  1.34,\n",
        "#         0.11,  1.1 ,  1.52, -0.96, -1.29, -0.71, -0.3 ,  1.46, -1.08,\n",
        "#         0.24, -0.  ,  0.28,  0.9 ,  0.75, -0.62, -0.71,  1.56, -0.33,\n",
        "#         0.14, -1.43, -0.66,  0.2 ])\n",
        "# y_scaled = np.array([-0.46,  0.63, -0.3 ,  0.66,  1.62, -0.55,  0.27, -1.03, -0.68,\n",
        "#         2.25, -1.25,  0.47, -0.51,  0.63, -0.62, -2.42, -0.76,  1.44,\n",
        "#        -0.12,  1.38,  1.6 , -1.22, -1.21, -0.63, -0.37,  1.24, -1.18,\n",
        "#         0.37,  0.17,  0.4 ,  0.88,  0.77, -0.49, -0.44,  1.63, -0.37,\n",
        "#         0.02, -1.36, -0.51,  0.07])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sgdxd-cp4VBx"
      },
      "source": [
        "*Please print the variables X_scaled and y_scaled to check if they are correct:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpgJWagDE-x9"
      },
      "source": [
        "...\n",
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6PcWKhwFML5"
      },
      "source": [
        "**Step 3: Create a model and fit it**\n",
        "\n",
        "The next step is to create a linear regression model and fit it using the existing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk6SGwfuFihF"
      },
      "source": [
        "*Please create and fit the model (fitting means, sklearn will estimate your parameters for a given Input using the specified model):*\n",
        "**Attention: Many times, sklearn needs input of a specific shape. If this is the case (as it will be here), you may be required to reshape data, even if is basically the same, e.g. reshaping a (n,) array to a (n,1) array.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5HYk7zYICma"
      },
      "source": [
        "model = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYmtW_4dFwfi"
      },
      "source": [
        "**Step 4: Get results**\n",
        "\n",
        "Once you have your model fitted, you can get the results to check whether the model works satisfactorily and interpret it.\n",
        "\n",
        "*Please obtain the coefficient of determination (ùëÖ¬≤):*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owg_cgsgF7Uf"
      },
      "source": [
        "r_sq = model. ...\n",
        "print('coefficient of determination:', r_sq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7IOBX0JGG9U"
      },
      "source": [
        "*Now, please also take a look at the estimated parameters for the intercept and the slope:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t08j85rGJiP"
      },
      "source": [
        "print('intercept:', ...)\n",
        "\n",
        "print('slope:', ...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKQtcJTsGRSO"
      },
      "source": [
        "The code above illustrates how to get ùëè‚ÇÄ and ùëè‚ÇÅ. You may notice that the intercept is a scalar, while the slope is an array, as you can have multiple independent variables (X)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQbgOa03Gcjq"
      },
      "source": [
        "**Step 5: Predict response**\n",
        "\n",
        "Once there is a satisfactory model, you can use it for predictions with either existing or new data.\n",
        "\n",
        "*To obtain the predicted response for X_scaled, change the following code:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn_1GeBTI1xm"
      },
      "source": [
        "y_pred = ...\n",
        "print('predicted response:', y_pred , sep='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmP1TirNI7UT"
      },
      "source": [
        "*Let's plot both original data and our predicted values as a line:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_zYLgzOJCCe"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(...)\n",
        "plt.plot(...)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj0pBvAEGyOU"
      },
      "source": [
        "In practice, regression models are often applied for forecasts.\n",
        "\n",
        "*Try to use the model to forecast a y value for a single random X value:*\n",
        "**Attention: Make sure, you provide your data in the correct format expected by your model - this can not be an integer ;)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5epV7S-MZsF"
      },
      "source": [
        "X = ...\n",
        "y_new = ...\n",
        "print(y_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmI6Szxaid4z"
      },
      "source": [
        "## Machine Learning Pipeline: Random Forest with Sklearn\n",
        "\n",
        "We will now execute a Machine Learning pipeline including data preparation, model training and performance evaluation using a Random Forest and a Linear Regression as a baseline model.\n",
        "\n",
        "We will use a dataset, where customers rated the quality of wine (For details, see: https://archive.ics.uci.edu/ml/datasets/Wine).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWmk2uMXYoRB"
      },
      "source": [
        "**Step 1: Data Preparation**\n",
        "\n",
        "\n",
        "*Please load the two datasets properly, and store them in two dataframes:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COtKM6dDRd5u"
      },
      "source": [
        "import pandas as pd\n",
        "url_white = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
        "url_red = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
        "\n",
        "df_white = ...\n",
        "df_red = ...\n",
        "\n",
        "print(df_white.shape,df_red.shape) # does this look resonable? Make sure you have the correct number of columns. If necessary, take a look at your data!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atoUpOnrMum_"
      },
      "source": [
        "*Now add a column \"color\" with the wine colors white = 0 or red = 1 respectively (to preserve this information) and combine both dataframes into one:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK9qxcwYMtuP"
      },
      "source": [
        "... # add color column to df_white\n",
        "... # add color column to df_red\n",
        "df_wines = ... # combine the two dataframes in a single long table\n",
        "\n",
        "print(df_wines.shape) # this should be (6497, 13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsIP2kuhMA68"
      },
      "source": [
        "Remember, we want to understand **what drives customer's quality perception for wines**. To accomplish that, we want to predict the perceived quality of a wine (our dependent variable, y) using all other available variables (indepentend variables, X).\n",
        "\n",
        "*Let's take a brief look at your dependend variable - how many wines per quality rating are there?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv32nSUxVLTR"
      },
      "source": [
        "... # create a table with the number of occurences per quality value (e.g., there should be 193 wines rated 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGgViSRJjy1s"
      },
      "source": [
        "*Now split the data in dependent (y) - quality - and independent(X) variable:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOIyY8IkMg3R"
      },
      "source": [
        "X,y = ...\n",
        "\n",
        "print(y.head(3))\n",
        "X.head(3) # Does this look good?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCcOLK-ZMkUI"
      },
      "source": [
        "**Step 2: Training**\n",
        "\n",
        "*Let's split the dataset so that 80% of the data is used to train the model and 20% is kept for future evaluation:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1LDvrZ5MorA"
      },
      "source": [
        "from sklearn.model_selection import ...\n",
        "X_train, X_test, y_train, y_test = ...\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FVKFEvSMtzc"
      },
      "source": [
        "Now we can define and fit our model on the training dataset. Let's do this for both a random forest and a linear regression model. Using two model will allow us to better evaluate our model performance in the end.\n",
        "\n",
        "*Please fit a linear regression and a random forest model:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q31IBY8OMw7k"
      },
      "source": [
        "from sklearn.ensemble import ... # take suitable random forest module\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model_rfo = ... # initialize random rorest model\n",
        "model_lin = ... # initialize linear regression model\n",
        "\n",
        "model_rfo.fit(...)\n",
        "model_lin.fit(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTwMheqMM0Kf"
      },
      "source": [
        "**Step 3: Performance Evaluation**\n",
        "\n",
        "*Now use the fitted model to evaluate performance on your 20% holdout test dataset, using the mean squared error (*MSE*) performance metric:*\n",
        "Note, that neither model had 'seen' this data before. This is crucial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E6JDqYOM7AR"
      },
      "source": [
        "from sklearn.metrics import ... # please use MSE\n",
        "\n",
        "y_hat_rfo = ... # make predictions using your random forest model\n",
        "y_hat_lin = ... # make predictions using your linear regression model\n",
        "\n",
        "mse_rfo = ... # calculate random forest prediction MSE\n",
        "mse_lin = ... # calculate linear regression prediction MSE\n",
        "\n",
        "print('MSE Random Forest: %.3f' % mse_rfo)\n",
        "print('MSE Linear Regression: %.3f' % mse_lin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHDkZUZMWP-B"
      },
      "source": [
        "<img src =\"https://i.ibb.co/Yyk6PBP/laughing-men-testing.jpg\" width=500 height=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyUb34dPpqdk"
      },
      "source": [
        "*It is always a good idea, to get a visual intuition as well, so let's quickly plot ground truth y_test against our predictions y_hat_rfo and y_hat_lin*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FtycYu3cdE-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "... # generate a scatter plot for your random forest predictions\n",
        "plt.show()\n",
        "\n",
        "... # generate a scatter plot for your linear regression predictions\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CN3utEwql_5"
      },
      "source": [
        "Taking both the MSE and the visual representation - which model performs better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK9El9w1qv1v"
      },
      "source": [
        "# write your answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QED3CFGxq1Wi"
      },
      "source": [
        "**Step 4: Generating Insights**\n",
        "\n",
        "Let's use our model to find out what is the most important variable for quality.\n",
        "\n",
        "*Please create a dataframe which has all the X variables and their respective performance and sort the dataframe by importance:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pacpzzrhd1fe"
      },
      "source": [
        "insights = pd.DataFrame(columns=['variable','importance'])\n",
        "\n",
        "insights['variable'] = ...\n",
        "insights['importance'] = ...\n",
        "\n",
        "insights. ... # please print the sorted table - what is most imporant?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Machine Learning Pipeline 1: Language Models using Huggingface\n",
        "\n",
        "Finally we will now analyze the sentiment of thousands of tweets. The dataset we use includes english tweets about how good or bad flying with a specific airline was. We will use these tweets to predict, if the content of the tweet is positive, neutral or negative.\n",
        "\n",
        "Because unstructured data in form of text is really hard to analyze for machine learning models we will now use a modern neural network. The neural net we will use is already trained to understand english language. In the upcoming cells we will download the model and train it (named fine-tuning) on the task of sentiment classification (e.g. predicting if the tweet is positive, neutral or negative in sentiment).\n",
        "\n",
        "We will use code from the website huggingface.com. A website that hosts many of the latest trained neural networks. By starting with an already pre-trained network we reduce the amount of work that we need to do by a lot.\n",
        "Many researchers today use such pre-trained models to then later train them to classify text, analyze images or other interesting data.\n",
        "\n",
        "**Please fill in all the ... in the upcoming cells to make your model work.** If you ever need more information feel free to google about the code or look specifically into the documentation of the huggingface code we will be using. Link: https://huggingface.co/docs"
      ],
      "metadata": {
        "id": "uEOBP9nzFwwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we install the transformer library (made by the huggingface team) that we need and import all needed packages"
      ],
      "metadata": {
        "id": "Sjp7SIepFUTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81I8SeZ1F56t",
        "outputId": "db692271-78c5-4d89-836a-f4a5fa4e59e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer,  AutoModelForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "z-TSr7ALGB8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To work with large language models like we are now doing, you need a graphics card (GPU). Run the next cell. If it outputs 'True', you are ready to continue.\n",
        "If the next cell outputs 'False', you need to activate your GPU in Google Colab.\n",
        "\n",
        "For that:\n",
        "\n",
        "1. Go to Menu at the top (Men√º oben) > Runtime (Laufzeit) > Change runtime (Laufzeittyp √§ndern).\n",
        "2. Change hardware acceleration to GPU (Hardwarebeschleuniger zu GPU)."
      ],
      "metadata": {
        "id": "8AeSIat2vX1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "qKJhtcQ4vGw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Data Preparation**"
      ],
      "metadata": {
        "id": "R1EUjacuGWwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_train = 'https://raw.githubusercontent.com/Maximilianwte/Data-Science-for-Customer-Insight/main/train.csv'"
      ],
      "metadata": {
        "id": "XXLcMVTxF5r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(..., index_col=0) # Load the data from the variable url_train into a pandas dataframe"
      ],
      "metadata": {
        "id": "_aOuh360pzN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we need to transform the labels from text values (e.g. 'positive') to numerical values, so that the model can understand these. For that we first build a small lambda function and apply it to our dataframe."
      ],
      "metadata": {
        "id": "d5sCr8hfF8Sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_label(x): # build a function that returns 2 if input x is 'positive', returns 1 if x == 'neutral' and else returns 0\n",
        "    if x == ...:\n",
        "      return 2\n",
        "    elif x == ...:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "df['airline_sentiment'] = df['airline_sentiment'].apply(lambda x: transform_label(x))"
      ],
      "metadata": {
        "id": "zU1tfiqR-kaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally lets explore our dataframe to check if our transformation worked."
      ],
      "metadata": {
        "id": "L8KpDgiTGdkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df. ... # Display the first five rows of the train dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bP3ctBUNyfo6",
        "outputId": "1df574a6-ed3e-47d6-b5d6-d57e0f58bf06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   airline_sentiment                                               text\n",
              "0                  1                @VirginAmerica What @dhepburn said.\n",
              "1                  2  @VirginAmerica plus you've added commercials t...\n",
              "2                  1  @VirginAmerica I didn't today... Must mean I n...\n",
              "3                  0  @VirginAmerica it's really aggressive to blast...\n",
              "4                  0  @VirginAmerica and it's a really big bad thing..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b690232b-ee46-4c2b-9bb4-88084c5b8225\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b690232b-ee46-4c2b-9bb4-88084c5b8225')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b690232b-ee46-4c2b-9bb4-88084c5b8225 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b690232b-ee46-4c2b-9bb4-88084c5b8225');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Loading model**\n",
        "\n",
        "Next we load a model from the Huggingface Libary. We use a model that is already trained to understand english. If you want to, you can try out other models from the website by copying in the model name into the variable below: https://huggingface.co/models."
      ],
      "metadata": {
        "id": "k4wBlql4GaC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1).to(\"cuda\")"
      ],
      "metadata": {
        "id": "fmENhUoHGh4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Building the datasets classes and converting the text data to text embeddings**"
      ],
      "metadata": {
        "id": "KbJ3RyUEHEy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the model we need a train and validation dataset. Therefore we split the loaded dataframe into train and val."
      ],
      "metadata": {
        "id": "37040fjsJt3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df.sample(frac=..., random_state=152) # Split the training data so that 20% are stored in df_val afterwards\n",
        "df_val = df.drop(...) # drop all rows that are in df_train, so that there are no tweets in val that are already in train\n",
        "len(df_val)"
      ],
      "metadata": {
        "id": "6gFeSj3nsmDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we convert the pandas dataframe into a dataset class, that makes it easier for the neural network to work with the data. You can write the code for such a dataset class yourself. You see the complete working class for this dataset below.\n",
        "\n",
        "Typically such a dataset class includes 2 methods. The __getitem__() method, that will return a specific tweet when you want to get an item as usual (e.g. train[2] to get item 2) and the __len__() method, that returns the amount of data in your dataset.\n",
        "\n",
        "Take a look at the class below to get an understanding. We put in the dataframe we loaded in previously as well as the tokenizer that will convert our tweets into numerical values so that the neural network can later work with it."
      ],
      "metadata": {
        "id": "Z3M5s9WK_6iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AirlineSentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length):\n",
        "        self.dataframe = dataframe\n",
        "        self.texts = self.dataframe.text.to_list()\n",
        "        self.text_embeddings = tokenizer(self.texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = self.dataframe.airline_sentiment.values\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.text_embeddings.items()}\n",
        "        item[\"labels\"] = torch.tensor(float(self.labels[idx]))\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "C0nOrW6jqn2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we now build an instance of our newly defined dataset class with our training and validation data. We then can use 'train_dataset' and 'val_dataset' in training the model."
      ],
      "metadata": {
        "id": "r-LLpju7A0fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 64 # the maximum words a tweet is analyzed for\n",
        "\n",
        "train_dataset = AirlineSentimentDataset(df_train, tokenizer, max_length)\n",
        "val_dataset = AirlineSentimentDataset(df_val, tokenizer, max_length)"
      ],
      "metadata": {
        "id": "-RI4SdEvqpXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Training the model**"
      ],
      "metadata": {
        "id": "VKIu6bKqHIRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets train the model. First we define the hyperparameters. These define for example how long the model should be trained or how many tweets the model should be trained on at each point in time."
      ],
      "metadata": {
        "id": "FQ0gosicKhHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size= ..., # set batch size for training to 32\n",
        "    per_device_eval_batch_size= ..., # also set the batch size for evaluation to 32\n",
        "    load_best_model_at_end= ..., # activate that the best model will be chosen after training\n",
        "    logging_steps=400,\n",
        "    save_steps=400,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    output_dir=\"/content/model\"\n",
        ")"
      ],
      "metadata": {
        "id": "sdpJXfusHTcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make the training work, the trainer must know if the model is getting better or not learning. Therefore here we define a metric for the trainer to use. Because we are doing classification we choose the accuracy score again."
      ],
      "metadata": {
        "id": "5pKzzl2FL5ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ... # load the accuracy_score from the sklearn library\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  predictions = pred.predictions.argmax(-1)\n",
        "  acc = ... (labels, predictions) # run the accuracy_score function with inputs labels and predictions\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "  }"
      ],
      "metadata": {
        "id": "aAMP4LEgrus3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define the trainer. The trainer is fitting the model parameters and minimizing the loss function to make the prediction as accurate as possible. You just need to define the trainer and afterwards start the training process. Then the model will get trained and we can use it to predict new data afterwards."
      ],
      "metadata": {
        "id": "o0Y5gz_SNKVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=..., # put in the model that we loaded a few cells ago\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "uCuvfxLQHXvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer. ... # train the model"
      ],
      "metadata": {
        "id": "OfxqrMW3HbwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Evaluation and prediction**"
      ],
      "metadata": {
        "id": "EpYFuducHKow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now after we trained the model lets evaluate the model by printing out some technical metrics."
      ],
      "metadata": {
        "id": "dRY0D8GVNZDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer. ... # use a built-in method to evaluate your trained model"
      ],
      "metadata": {
        "id": "yprnhpzmHfyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As our last task lets define a function that predicts the sentiment of any statement you put in using our new model."
      ],
      "metadata": {
        "id": "O6PMlj2tNk8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(text):\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, max_length=64, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model(**inputs)\n",
        "    probs = outputs[0].softmax(1)\n",
        "    classes = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "    return classes[int(probs.cpu().detach().numpy()[0][0])]"
      ],
      "metadata": {
        "id": "cNC5x7ApHlVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now test how good your model is. Try out any text to see if your model predicts the sentiment correctly.. and is your model good?"
      ],
      "metadata": {
        "id": "j02DJ4wNNuI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_prediction('...') # Come up with a sentence try your newly built model"
      ],
      "metadata": {
        "id": "9DF72LcqCszn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save your model so that you can use it in the future."
      ],
      "metadata": {
        "id": "Ol8zC5qqN357"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model. ... # save your model"
      ],
      "metadata": {
        "id": "5Zb-RQpct2IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tClVksnmXsNn"
      },
      "source": [
        "## Save & Submit\n",
        "\n",
        "Please make sure you included your name and matrikel at the top of this notebook, save your work **with your name in the file name**, and send **two** files to maximilian.witte@uni-hamburg.de:\n",
        "- Ipynb *(Go to File -> Download .ipynb)*\n",
        "- PDF *(Go to File -> Print -> Save as PDF)* (optional)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DPboysUljWFD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}